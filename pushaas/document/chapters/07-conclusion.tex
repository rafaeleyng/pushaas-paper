\section{Conclusion} \label{section-conclusion}

This work aimed to provide an implementation of a server push service for client applications running on top of the Tsuru platform, in a convenient way to allow for easy provisioning and integration with applications. Besides the convenience, the system also focused on delivering a well-designed architecture to allow for horizontal scaling and handling of significant loads.

The Push Service was able to leverage the existing Nginx Push Stream module, a high-performance tool used in large real-world system, to compose a larger system focused on providing horizontal scalability and an extra layer of features useful for organizations. The PushaaS was able to take the Push Service and abstract its usage by offering it as a cloud service. The integration of the service with the Tsuru platform was successful and its usage via Tsuru was perceived by Tsuru users as very familiar and similar to other existing and more established services.

The evaluation process conducted showed a positive reception of the service by Tsuru users, which considered relevant the problem the system solves, and considered the implementation a savvy approach to the problem. While the general reception was positive, various attention points were raised, constituting a valuable source of improvements to be made on future work.

The system presents some important extension points, that while received at least a basic implementation, should be extended in order for the system to really achieve a desired level of flexibility to make it useful in more scenarios:

\begin{itemize}
    \item provisioners: the development and evaluation processes provisioned infrastructure components on Amazon ECS. Organizations willing to adopt the system would likely have other infrastructure providers, so the development of new provisioners would be needed. This is the main extension point in the system, and the implementation of new provisioners should be fairly trivial. The pushaas application already supports configuration of the chosen provisioner as an application-level configuration.
    \item plans: somewhat related to the provisioners, Push Service instances, when created, are sized according to the chosen plan for the service instance. The system was implemented with a single, default, "small" plan for service instances. While this is acceptable for the evaluation purposes, usage of the system on real-world scenarios requires allowing the developer to have control over the sizing of the service instance, both on the vertical aspect (the computational power to be allocated for components) and on the horizontal aspect (the number of replicas of components, to achieve high availability and allow load balancing between instances). Also, aspects of auto-scaling were ignored on this work, but should be considered as an improvement on top of plans.
    \item authentication: the system proposed an authenticated publishing interface, overcoming the limitation of the Nginx Push Stream module. The current implementation only supports HTTP basic authentication, but organizations often need more complex authentication schemes, specially to allow integration with existing platforms. The addition of extra authentication schemes should also be fairly trivial.
\end{itemize}

The Push Service architecture was designed as a collaboration of several uncoupled and mostly stateless components, which can be replicated to support higher loads. While this architecture is known from the author experience to allow for horizontal scaling, and was generally perceived as able to horizontally scale by the interviewees, no actual performance tests or benchmarks were performed.

The PushaaS application itself resulted in an inexpensive application, with little infrastructure requirements - only a Redis instance for data storing and job scheduling, besides the application itself, so the adoption of the PushaaS system and its integration with an existing Tsuru cluster should be a simple process.
